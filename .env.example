# ========================================
# FOREX BOT CONFIGURATION
# ========================================
# Copy this file to .env and customize for your setup
# All settings have safe defaults that work on any hardware

# ========================================
# CORE THREADING CONTROLS
# ========================================
# Maximum CPU threads per process
# Safe default: 8 (works on 1-252 cores)
# Recommended: 4-8 for most setups
FOREX_BOT_CPU_THREADS=8

# Feature engineering workers (for parallel indicator calculation)
# Safe default: 8 (auto-capped in code)
# DO NOT set above 16 even on HPC systems
FOREX_BOT_FEATURE_WORKERS=8

# TA-Lib parallel workers
# Safe default: 8 (auto-capped in code)
FOREX_BOT_TALIB_WORKERS=8

# ========================================
# SYMBOL EXECUTION CONTROL
# ========================================
# Maximum symbols to trade simultaneously
# Safe default: 1 (sequential execution)
# Recommended: 1-2 for most systems, max 4 on HPC
# Each symbol spawns its own models, features, etc.
FOREX_BOT_MAX_CONCURRENT_SYMBOLS=1

# ========================================
# BLAS/LAPACK THREADING
# ========================================
# NumPy/SciPy linear algebra threads per process
# Safe default: 4 (auto-configured in code)
# Lower = less contention when running parallel processes
OMP_NUM_THREADS=4
MKL_NUM_THREADS=4
OPENBLAS_NUM_THREADS=4
NUMEXPR_NUM_THREADS=4

# ========================================
# MODEL TRAINING
# ========================================
# Training data size limits (0 = unlimited)
# Use this to prevent OOM on systems with limited RAM
FOREX_BOT_MAX_TRAINING_ROWS=0

# Use full dataset for training (overrides row limits)
# Set to 0 or false to use limits
FOREX_BOT_FULL_DATA=0

# ========================================
# PERFORMANCE TUNING
# ========================================
# Enable training frame caching (speeds up multi-symbol training)
# Only enable if you have enough RAM (2GB+ per symbol)
FOREX_BOT_CACHE_TRAINING_FRAMES=false

# Maximum cache size in bytes (2GB default)
FOREX_BOT_TRAINING_CACHE_MAX_BYTES=2000000000

# Enable parquet memory mapping for faster reads
FOREX_BOT_PARQUET_MEMORY_MAP=true

# ========================================
# DATA STORAGE
# ========================================
# Directory for market data (parquet files)
FOREX_BOT_DATA_DIR=data

# Directory for trained models
FOREX_BOT_MODELS_DIR=models

# Directory for cache files
FOREX_BOT_CACHE_DIR=cache

# Directory for logs
LOG_DIR=logs
LOG_FILE=forex_bot.log

# ========================================
# METATRADER 5 CONNECTION
# ========================================
# MT5 is required for live trading and data download
# Set to false for training-only mode
FOREX_BOT_MT5_REQUIRED=true

# MT5 terminal path (auto-detected on Windows if not set)
# Example: C:\Program Files\MetaTrader 5\terminal64.exe
# FOREX_BOT_MT5_TERMINAL_PATH=

# MT5 login credentials
# FOREX_BOT_MT5_LOGIN=
# FOREX_BOT_MT5_PASSWORD=
# FOREX_BOT_MT5_SERVER=

# MT5 broker timezone offset from UTC (auto-detected if not set)
# Example: +2 for EET, -5 for EST
FOREX_BOT_MT5_TIMEZONE_OFFSET=0

# ========================================
# HARDWARE-SPECIFIC OPTIMIZATION
# ========================================
# These are auto-detected but can be overridden

# Is this a high-performance computing (HPC) system?
# Auto-detected: True if cores > 64
# FOREX_BOT_IS_HPC=

# GPU devices to use (comma-separated)
# Example: 0,1,2,3 for 4 GPUs
# Leave empty for CPU-only or auto-detection
# FOREX_BOT_GPU_DEVICES=

# CPU threads per GPU for multi-GPU training
# FOREX_BOT_CPU_THREADS_PER_GPU=

# ========================================
# SAFETY LIMITS
# ========================================
# These prevent resource exhaustion on any system

# Maximum parallel model training workers (per symbol)
# Safe default: Configured dynamically based on CPU threads
# The code automatically divides available threads

# Maximum evolution CMA-ES islands
# Hard-capped at 8 in code regardless of CPU count

# Maximum concurrent models per worker
# Hard-capped at 4 in code

# ========================================
# RECOMMENDED CONFIGURATIONS
# ========================================

# LOW-END SYSTEM (1-4 cores, 8-16GB RAM):
# FOREX_BOT_CPU_THREADS=2
# FOREX_BOT_FEATURE_WORKERS=2
# FOREX_BOT_MAX_CONCURRENT_SYMBOLS=1
# OMP_NUM_THREADS=1
# MKL_NUM_THREADS=1

# MEDIUM SYSTEM (8-16 cores, 32GB RAM):
# FOREX_BOT_CPU_THREADS=8
# FOREX_BOT_FEATURE_WORKERS=8
# FOREX_BOT_MAX_CONCURRENT_SYMBOLS=2
# OMP_NUM_THREADS=4
# MKL_NUM_THREADS=4

# HIGH-END WORKSTATION (24-48 cores, 128GB RAM):
# FOREX_BOT_CPU_THREADS=8
# FOREX_BOT_FEATURE_WORKERS=8
# FOREX_BOT_MAX_CONCURRENT_SYMBOLS=4
# OMP_NUM_THREADS=4
# MKL_NUM_THREADS=4

# HPC CLUSTER (252 cores, 500GB+ RAM):
# FOREX_BOT_CPU_THREADS=8
# FOREX_BOT_FEATURE_WORKERS=8
# FOREX_BOT_MAX_CONCURRENT_SYMBOLS=1
# OMP_NUM_THREADS=4
# MKL_NUM_THREADS=4
# Note: Use environment orchestrator (SLURM, PBS) to spawn multiple
# instances across nodes rather than high MAX_CONCURRENT_SYMBOLS

# ========================================
# TROUBLESHOOTING
# ========================================

# If experiencing thread contention or slow performance:
# 1. Lower FOREX_BOT_CPU_THREADS to 4
# 2. Set MAX_CONCURRENT_SYMBOLS to 1
# 3. Set BLAS threads to 1-2

# If experiencing memory issues:
# 1. Set FOREX_BOT_MAX_TRAINING_ROWS to limit data size
# 2. Disable FOREX_BOT_CACHE_TRAINING_FRAMES
# 3. Reduce FOREX_BOT_MAX_CONCURRENT_SYMBOLS to 1

# If models train too slowly:
# 1. Increase FOREX_BOT_CPU_THREADS to 8-16
# 2. Ensure BLAS threads are 4-8
# 3. Check that you're not running other heavy processes
