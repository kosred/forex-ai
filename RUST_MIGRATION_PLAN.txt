================================================================================
PYTHON TO RUST MIGRATION PLAN - FOREX AI TRADING SYSTEM
GIL-FREE, HIGH-PERFORMANCE ARCHITECTURE
================================================================================

MIGRATION STATUS: Phase 1 - Planning Complete
Last Updated: 2026-01-06

================================================================================
TIER 1: PRODUCTION-READY RUST LIBRARIES (USE IMMEDIATELY)
================================================================================

TREE MODELS (GRADIENT BOOSTING) - PRIORITY: CRITICAL
â”œâ”€ XGBoost       â†’ xgboost-rust 0.1.0      â­â­â­â­â­
â”œâ”€ LightGBM      â†’ lightgbm-rust 0.1.1     â­â­â­â­â­
â””â”€ CatBoost      â†’ catboost-rust 0.3.6     â­â­â­â­â­
   Status: FFI bindings to C++ libraries (same as Python)
   Impact: 70% of models GIL-free
   Timeline: 1 week

DATA PROCESSING - PRIORITY: CRITICAL
â”œâ”€ Pandas        â†’ polars 0.52.0           â­â­â­â­â­ (30x faster)
â”œâ”€ NumPy         â†’ ndarray 0.17 + rayon    â­â­â­â­â­ (already using)
â””â”€ scikit-learn  â†’ linfa                   â­â­â­â­â­ (25x faster)
   Status: Production ready
   Impact: Foundation for everything
   Timeline: 2 weeks

SPECIALIZED MODELS - PRIORITY: HIGH
â”œâ”€ KAN           â†’ burn-efficient-kan 0.1.2 â­â­â­â­â­ (Pure Rust!)
â”œâ”€ CMA-ES        â†’ cmaes 0.2.1              â­â­â­â­â­
â”œâ”€ Genetic Algo  â†’ genevo, genetic_algorithm â­â­â­â­â­
â””â”€ Clustering    â†’ linfa-clustering         â­â­â­â­â­
   Status: Ready to use
   Timeline: 2-3 weeks

================================================================================
TIER 2: BURN FRAMEWORK (IMPLEMENT IN PURE RUST)
================================================================================

PRIMARY DEEP LEARNING FRAMEWORK: Burn
- Multi-backend: CUDA, WGPU, NdArray
- Pure Rust, production-ready
- GPU acceleration built-in

MODELS TO IMPLEMENT:
â”œâ”€ MLP           â†’ burn::nn (built-in)      Difficulty: â­ (1 week)
â”œâ”€ LSTM/RNN      â†’ burn::nn::lstm           Difficulty: â­â­ (2 weeks)
â”œâ”€ CNN/ResNet    â†’ burn::nn::conv           Difficulty: â­â­ (2 weeks)
â”œâ”€ VAE           â†’ Tutorial available       Difficulty: â­â­â­ (3 weeks)
â”œâ”€ GAN           â†’ Burn WGAN example        Difficulty: â­â­â­ (3 weeks)
â”œâ”€ NBEATS        â†’ Custom (MLP-based)       Difficulty: â­â­â­ (3 weeks)
â”œâ”€ TiDE          â†’ Custom (encoder-decoder) Difficulty: â­â­â­ (3 weeks)
â””â”€ TabNet        â†’ Custom (attention)       Difficulty: â­â­â­â­ (4 weeks)

RESOURCES:
- Burn VAE Tutorial (Dec 2025): https://medium.com/@alfred.weirich/...
- ClawFoxyVision: LSTM/GRU time series examples
- Official Burn repo: WGAN MNIST example

================================================================================
TIER 3: CANDLE FRAMEWORK (FOR TRANSFORMERS)
================================================================================

USE FOR: Transformer-based models
- HuggingFace integration
- FlashAttention v3 support
- Pre-built architectures

MODELS:
â”œâ”€ Transformers  â†’ candle-transformers      â­â­â­â­â­
â”œâ”€ Self-Attentionâ†’ candle-flash-attn-3      â­â­â­â­â­
â”œâ”€ BERT/GPT2     â†’ rust-bert                â­â­â­â­â­
â””â”€ Tokenizers    â†’ tokenizers (HuggingFace) â­â­â­â­â­

Timeline: 2-3 weeks

================================================================================
TIER 4: MUONTS - GLUONTS MODELS IN RUST!
================================================================================

CRITICAL DISCOVERY: MuonTS ports GluonTS models to Rust using Burn

CONFIRMED MODELS:
â””â”€ TFT (Temporal Fusion Transformer) âœ… IMPLEMENTED
   Docs: https://docs.rs/muonts/latest/muonts/models/tft/tfe/

LIKELY MODELS (needs verification):
â”œâ”€ DeepAR        âš ï¸ (GluonTS model, likely in MuonTS)
â””â”€ Other GluonTS models

ACTION: Investigate MuonTS immediately - could replace NBEATS, TiDE!
Timeline: 1 week investigation

================================================================================
TIER 5: STRATEGIC ALTERNATIVES (ONNX EXPORT)
================================================================================

REINFORCEMENT LEARNING
â”œâ”€ Python: stable-baselines3, tianshou
â”œâ”€ Rust: border (DQN, SAC, IQN) - immature
â””â”€ STRATEGY: Train in Python â†’ Export to ONNX â†’ Inference in Rust (ort)
   Impact: No runtime GIL, policies run in Rust

NORMALIZING FLOWS
â”œâ”€ Python: normflows, etc.
â”œâ”€ Rust: None found
â””â”€ STRATEGY: Implement in Burn OR train in Python â†’ ONNX export
   Priority: Low (unless critical)

METATRADER 5 INTEGRATION - CRITICAL
â”œâ”€ Option A: Rust FFI bindings (rust-bindgen)  â­â­â­â­ Very Hard
â”œâ”€ Option B: REST API (mt5-rest)               â­â­ Medium
â””â”€ Option C: Python subprocess                 â­ Easy
   RECOMMENDATION: Start with C, migrate to B, then A if needed
   Impact: Critical for trading execution

================================================================================
IMPLEMENTATION PHASES
================================================================================

PHASE 1: QUICK WINS (2-3 weeks) - START HERE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Tree Models (xgboost-rust, lightgbm-rust)    â”‚
â”‚    - Add to forex-models Cargo.toml             â”‚
â”‚    - Create wrapper API                          â”‚
â”‚    - Test with existing data                     â”‚
â”‚    Timeline: 1 week                              â”‚
â”‚                                                  â”‚
â”‚ 2. Data Processing (polars, ndarray)            â”‚
â”‚    - Port data loading to polars                 â”‚
â”‚    - Replace pandas operations                   â”‚
â”‚    Timeline: 1 week                              â”‚
â”‚                                                  â”‚
â”‚ 3. Feature Engineering (linfa)                   â”‚
â”‚    - Port sklearn preprocessing                  â”‚
â”‚    Timeline: 1 week                              â”‚
â”‚                                                  â”‚
â”‚ RESULT: 70-80% of models GIL-free, 10-30x speed â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 2: DEEP LEARNING FOUNDATION (3-4 weeks)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Set up Burn framework                        â”‚
â”‚    - Add burn dependencies                       â”‚
â”‚    - Configure CUDA backend                      â”‚
â”‚    Timeline: 3 days                              â”‚
â”‚                                                  â”‚
â”‚ 2. MLP + KAN                                     â”‚
â”‚    - Implement MLP using burn::nn                â”‚
â”‚    - Integrate burn-efficient-kan                â”‚
â”‚    Timeline: 1 week                              â”‚
â”‚                                                  â”‚
â”‚ 3. LSTM/RNN                                      â”‚
â”‚    - Use burn::nn::lstm                          â”‚
â”‚    - Port existing LSTM models                   â”‚
â”‚    Timeline: 2 weeks                             â”‚
â”‚                                                  â”‚
â”‚ 4. Investigate MuonTS                            â”‚
â”‚    - Test TFT model                              â”‚
â”‚    - Check for DeepAR, other models              â”‚
â”‚    Timeline: 1 week                              â”‚
â”‚                                                  â”‚
â”‚ RESULT: Core DL ready, GPU acceleration enabled â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 3: SPECIALIZED MODELS (4-6 weeks)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Transformers (candle-transformers, rust-bert)â”‚
â”‚    Timeline: 2 weeks                             â”‚
â”‚                                                  â”‚
â”‚ 2. NBEATS (Burn OR MuonTS)                       â”‚
â”‚    Timeline: 3 weeks                             â”‚
â”‚                                                  â”‚
â”‚ 3. TiDE (Burn OR MuonTS)                         â”‚
â”‚    Timeline: 3 weeks                             â”‚
â”‚                                                  â”‚
â”‚ 4. TabNet (Burn implementation OR ONNX)          â”‚
â”‚    Timeline: 4 weeks                             â”‚
â”‚                                                  â”‚
â”‚ 5. VAE/GAN (Burn examples)                       â”‚
â”‚    Timeline: 3 weeks                             â”‚
â”‚                                                  â”‚
â”‚ RESULT: All models except RL in pure Rust       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 4: PRODUCTION DEPLOYMENT (2-3 weeks)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. MT5 Integration                               â”‚
â”‚    - Start: Python subprocess                    â”‚
â”‚    - Later: REST API (mt5-rest)                  â”‚
â”‚    Timeline: 2 weeks                             â”‚
â”‚                                                  â”‚
â”‚ 2. RL Policies                                   â”‚
â”‚    - Train in Python                             â”‚
â”‚    - Export to ONNX                              â”‚
â”‚    - Load in Rust via ort                        â”‚
â”‚    Timeline: 1 week                              â”‚
â”‚                                                  â”‚
â”‚ 3. Normalizing Flows (optional)                  â”‚
â”‚    - ONNX export or skip                         â”‚
â”‚                                                  â”‚
â”‚ RESULT: 95%+ GIL-free, production-ready          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

================================================================================
FINAL ARCHITECTURE (100% GIL-FREE)
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RUST MAIN RUNTIME (forex-cli binary)          â”‚
â”‚  âœ… No GIL, full multi-core parallelism         â”‚
â”‚  âœ… GPU acceleration (CUDA)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       â”‚       â”‚
Data Layer  ML      Training
    â”‚       â”‚       â”‚
polars  Tree Models  Burn
ndarray ONNX (ort)   Rayon
linfa   Burn models  CUDA
        Candle
        MuonTS
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚
MT5 (Process)   RL (Offline)
    â”‚               â”‚
REST API    Pythonâ†’ONNX
Subprocess  Load in Rust
No GIL      No runtime GIL

================================================================================
DEPENDENCY ADDITIONS
================================================================================

[forex-models/Cargo.toml]
xgboost-rust = "0.1.0"
lightgbm-rust = "0.1.1"
catboost-rust = "0.3.6"
burn = "0.19.0"
burn-cuda = "0.19.0"
burn-efficient-kan = "0.1.2"
ort = "2.0.0-rc.10"  # ONNX runtime
muonts = "*"  # Check latest version

[forex-data/Cargo.toml]
polars = "0.52.0"
linfa = "*"
linfa-clustering = "*"

[forex-bindings/Cargo.toml]
# Already has pyo3, numpy

[NEW: forex-transformers/Cargo.toml]
candle-core = "*"
candle-transformers = "*"
candle-flash-attn-3 = "*"
rust-bert = "*"
tokenizers = "*"

================================================================================
CRATE STRUCTURE
================================================================================

forex-ai/
â”œâ”€ crates/
â”‚  â”œâ”€ forex-core/         âœ… Done (config, logging, storage, system)
â”‚  â”œâ”€ forex-data/         ğŸ”„ In Progress (add polars, linfa)
â”‚  â”œâ”€ forex-models/       ğŸ”„ Expand (add tree models, burn, ort)
â”‚  â”œâ”€ forex-search/       âœ… Done (genetic algorithms)
â”‚  â”œâ”€ forex-bindings/     ğŸ”„ Expand (expose more to Python)
â”‚  â”œâ”€ forex-cli/          ğŸ”„ Update (main Rust runtime)
â”‚  â””â”€ forex-transformers/ âŒ NEW (candle, rust-bert)
â””â”€ src/forex_bot/         ğŸ”„ Keep for training, export ONNX

================================================================================
KEY RESOURCES
================================================================================

CRATES:
- burn-efficient-kan: https://crates.io/crates/burn-efficient-kan
- MuonTS: https://lib.rs/crates/muonts
- MuonTS TFT docs: https://docs.rs/muonts/latest/muonts/models/tft/
- Candle: https://github.com/huggingface/candle
- rust-bert: https://github.com/guillaume-be/rust-bert
- linfa: https://github.com/rust-ml/linfa
- polars: https://github.com/pola-rs/polars

TUTORIALS:
- Burn VAE: https://medium.com/@alfred.weirich/rust-burn-building-a-variational-autoencoder-for-mnist-part-4-b9c345b96421
- ClawFoxyVision: https://github.com/rustic-ml/ClawFoxyVision
- Candle tutorial: https://github.com/ToluClassics/candle-tutorial

BENCHMARKS:
- Linfa 25x faster: https://lpalmieri.com/posts/2019-12-01-taking-ml-to-production-with-rust-a-25x-speedup/
- Polars 30x faster: https://towardsdatascience.com/rust-polars-unlocking-high-performance-data-analysis-part-1-ce42af370ece/

================================================================================
IMMEDIATE NEXT STEPS
================================================================================

RECOMMENDED START: Option 1 - Port Tree Models

[ ] 1. Add tree model dependencies to forex-models/Cargo.toml
[ ] 2. Create tree_models.rs module
[ ] 3. Implement wrappers for XGBoost, LightGBM, CatBoost
[ ] 4. Write tests with existing data
[ ] 5. Update forex-bindings to expose tree models to Python
[ ] 6. Benchmark vs Python implementations

ALTERNATIVE: Option 2 - Investigate MuonTS + Burn

[ ] 1. Add muonts and burn to Cargo.toml
[ ] 2. Test MuonTS TFT model
[ ] 3. Implement simple MLP in Burn
[ ] 4. Test GPU acceleration
[ ] 5. Document findings

ALTERNATIVE: Option 3 - Data Pipeline

[ ] 1. Add polars to forex-data/Cargo.toml
[ ] 2. Port data loading from pandas to polars
[ ] 3. Add linfa for feature engineering
[ ] 4. Create Rust data pipeline
[ ] 5. Benchmark performance

================================================================================
SUCCESS METRICS
================================================================================

Phase 1 Complete:
âœ… Tree models running in Rust
âœ… 10-30x speedup vs Python
âœ… 70% of models GIL-free
âœ… Data pipeline in polars

Phase 2 Complete:
âœ… Burn framework integrated
âœ… MLP, LSTM, KAN working
âœ… GPU acceleration enabled
âœ… MuonTS evaluated

Phase 3 Complete:
âœ… Transformers via Candle
âœ… NBEATS, TiDE implemented
âœ… 95% of models in Rust

Phase 4 Complete:
âœ… MT5 integration working
âœ… RL policies via ONNX
âœ… 100% production deployment
âœ… Full GIL-free runtime

================================================================================
RISK MITIGATION
================================================================================

Risk: Complex models hard to implement in Rust
Mitigation: Use ONNX export for edge cases, prioritize high-impact models

Risk: MT5 integration breaks
Mitigation: Start with Python subprocess, gradual migration to REST/FFI

Risk: Performance not as expected
Mitigation: Benchmark each phase, compare with Python baseline

Risk: GPU compatibility issues
Mitigation: Test on target hardware early, Burn supports multiple backends

Risk: Team learning curve
Mitigation: Start with simple models, extensive documentation, gradual rollout

================================================================================
TIMELINE SUMMARY
================================================================================

Total Estimated Time: 11-17 weeks (3-4 months)

Week 1-3:   Phase 1 (Quick Wins)
Week 4-7:   Phase 2 (Deep Learning Foundation)
Week 8-13:  Phase 3 (Specialized Models)
Week 14-17: Phase 4 (Production Deployment)

CRITICAL PATH:
1. Tree models (Week 1)
2. Data pipeline (Week 2-3)
3. Burn setup (Week 4)
4. MuonTS investigation (Week 5)
5. Core models (Week 6-10)
6. MT5 integration (Week 14-15)

================================================================================
NOTES
================================================================================

- Python bindings ONLY for training complex models, NOT runtime inference
- All inference must be GIL-free (Rust or ONNX)
- GPU acceleration critical for deep learning models
- MuonTS could significantly reduce implementation time
- Prioritize high-impact, low-risk migrations first
- Keep Python codebase for model development/experimentation
- Export to ONNX for production deployment

================================================================================
END OF MIGRATION PLAN
================================================================================
